
<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Pengfei Ren</title>
	<meta content="Pengfei Ren, PengfeiRen96.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 900px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul { 
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
		
img.clustrmaps-widget {
  margin-bottom: 0.5em;
  float: left;
  width: 25%;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');



</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Pengfei" style="float: left; padding-left: .01em; height: 140px;" src="pfren.jpg" />
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Pengfei Ren</span><br />
<span><strong>Email  </strong>: rpf@bupt.edu.cn</span> <br /> 
<span>Currently, I am a postdoctoral researcher in the School of Computer Science, Beijing University of Posts and Telecommunications (BUPT, China). I received my Ph.D. degree from Beijing University of Posts and Telecommunications in 2022, advised by Prof. <a href='https://scholar.google.com/citations?user=H441DjwAAAAJ&hl=en'>Jingyu Wang</a> and  Prof. <a href='https://kyy.bupt.edu.cn/info/1010/3321.htm'>Jianxin Liao</a>. 
My research work focuses on 3D Hand Reconstruction, Gesture Recognition, and Video Grounding.

</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<p style="text-align:center">
   <a href="https://scholar.google.com/citations?user=TzpecsAAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a> &nbsp/&nbsp
   <a href="https://github.com/PengfeiRen96" target="_blank">Github</a> &nbsp/&nbsp
   <a href="https://www.researchgate.net/profile/Ren-Pengfei" target="_blank"> Researchgate </a>
</p>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul> 
    <li> <font color="#FF0000"> June, 2025: Two papers have been accepted by ICCV 2025.</font> </li>
    <li> May, 2025: One paper has been accepted by IJCAI 2025.</font> </li>
    <li> Feb, 2025: One paper has been accepted by CVPR 2025.</font> </li>
    <li> Jan, 2025: One paper has been accepted by CSCW 2025.</font> </li>
    <li> Aug, 2024: One paper has been accepted by ECCV 2024.</font> </li>
    <li> Jun, 2024: One paper has been accepted by MM 2024.</font> </li>
    <li> Apr, 2024: One paper has been accepted by IJCAI 2024.</font> </li>
    <li> <font color="#FF0000">Apr, 2024: One paper was selected as Highlight by CVPR 2024!</font> </li>
    <li> <font color="#FF0000">Feb, 2024: Two papers have been accepted by CVPR 2024.</font> </li>
    <li> Dec, 2023: One paper has been accepted by AAAI 2024.</li>
    <li> Dec, 2023: One paper has been accepted by ICASSP 2024.</li>
    <li> <font color="#FF0000">Aug, 2023: DIR was selected as Oral by ICCV 2023!</font> </li>
    <li> June, 2023: Two paper has been accepted by ICCV 2023.</li>
    <li> <font color="#FF0000">June, 2023: RDFNet was selected as Oral by ECAI 2023!</font> </li>
    <li> June, 2023: One paper has been accepted by ECAI 2023 .</li>
    <li> <font color="#FF0000">Feb, 2023: IPNet won the Distinguished Paper Award of AAAI 2023 (0.13%, 12 of 8777 submissions)!</font> </li>	    
    <li> Jan, 2023: IPNet was selected as Oral by AAAI 2023. </li>
    <li> Jan, 2023: One paper has been accepted by WWW 2023. </li>
    <li> Nov, 2022: One paper has been accepted by AAAI 2023. </li>
    <li> Jul, 2022: One paper has been accepted by ECCV 2022. </li>
    <li> May, 2022: One paper has been accepted by TIP 2022. </li>	    
    <li> Mar, 2022: One paper has been accepted by CVPR 2022. </li>
    </li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications (* Co-first Author,  &#8225 Corresponding Author)</h2>



<div class="paper" id="A3-Net"><img class="paper" src="paper/A3-Net.png" title="A3-Net: Calibration-Free Multi-View 3D Hand Reconstruction for Enhanced Musical Instrument Learning." />
<div> <strong>A3-Net: Calibration-Free Multi-View 3D Hand Reconstruction for Enhanced Musical Instrument Learning.</strong><br />
Geng Chen, Xufeng Jian, Yuchen Chen, <strong>Pengfei Ren&#8225</strong>, Jingyu Wang, Haifeng Sun, Qi Qi, Jing Wang, Jianxin Liao. <br />
International Joint Conference on Artificial Intelligence <strong>(IJCAI, CCF-A)</strong>, 2025 <br />
<a href=''>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

	
<div class="paper" id="PGTE"><img class="paper" src="paper/PGTE.png" title="Pose-Guided Temporal Enhancement for Robust Low-Resolution Hand Reconstruction" />
<div> <strong>Pose-Guided Temporal Enhancement for Robust Low-Resolution Hand Reconstruction</strong><br />
Kaixin Fan, <strong>Pengfei Ren*</strong>, Jingyu Wang, Haifeng Sun, Qi Qi, Zirui Zhuang, Jianxin Liao.<br />
Proceedings of the Computer Vision and Pattern Recognition Conference <strong>(CVPR, CCF-A)</strong>, 2025 <br />
<a href=''>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

	
<div class="paper" id="BareHand"><img class="paper" src="paper/BareHand.png" title="Towards Bare-Hand Interaction for Whiteboard Collaboration in Virtual Reality" />
<div> <strong>Towards Bare-Hand Interaction for Whiteboard Collaboration in Virtual Reality</strong><br />
Guangtian Liu, Haonan Su, Jingyu Wang, Qi Qi, Haifeng Sun, Zirui Zhuang, <strong>Pengfei Ren&#8225</strong>, Jianxin Liao<br />
ACM SIGCHI Conference on Computer-Supported Cooperative Work & Social Computing <strong>(CSCW, CCF-A)</strong>, 2025 <br />
<a href=''>[PDF]</a>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="CFI"><img class="paper" src="paper/CFI.png" title="Coarse-to-Fine Implicit Representation Learning for 3D Hand-Object Reconstruction from a Single RGB-D Image" />
<div> <strong>Coarse-to-Fine Implicit Representation Learning for 3D Hand-Object Reconstruction from a Single RGB-D Image</strong><br />
Xingyu Liu, <strong>Pengfei Ren*</strong>, Jingyu Wang, Haifeng Sun, Qi Qi, Zirui Zhuang, Jianxin Liao <br />
European Conference on Computer Vision <strong>(ECCV)</strong>, 2024 <br />
<a href=''>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="SDPNet"><img class="paper" src="paper/SDPNet.png" title="Dynamic Support Information Mining for Category-Agnostic Pose Estimation" />
<div> <strong>Dynamic Support Information Mining for Category-Agnostic Pose Estimation</strong><br />
<strong>Pengfei Ren</strong>, Yuanyuan Gao, Haifeng Sun, Qi Qi, Jingyu Wang, Jianxin Liao <br />
IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR, CCF-A)</strong>, 2024 <br />
<a href='https://openaccess.thecvf.com/content/CVPR2024/papers/Ren_Dynamic_Support_Information_Mining_for_Category-Agnostic_Pose_Estimation_CVPR_2024_paper.pdf'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="MSNet"><img class="paper" src="paper/MSNet.png" title="Multi-Scale Video Anomaly Detection by Multi-Grained Spatio-Temporal Representation Learning" />
<div> <strong>Multi-Scale Video Anomaly Detection by Multi-Grained Spatio-Temporal Representation Learning</strong><br />
Menghao Zhang, Jingyu Wang, Qi Qi, Haifeng Sun, Zirui Zhuang, <strong>Pengfei Ren</strong>, Ruilong Ma, Jianxin Liao <br />
IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR, CCF-A)</strong>, <strong><font color="#FF0000">Highlight</font></strong>, 2024 <br />
<a href=''>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="KFNet"><img class="paper" src="paper/KFNet.png" title="Keypoint Fusion for RGB-D Based 3D Hand Pose Estimation" />
<div> <strong>Keypoint Fusion for RGB-D Based 3D Hand Pose Estimation</strong><br />
Xingyu Liu, <strong>Pengfei Ren*</strong>, Yuanyuan Gao, Jingyu Wang, Haifeng Sun, Qi Qi, Jianxin Liao <br />
AAAI Conference on Artificial Intelligence <strong>(AAAI, CCF-A)</strong>, 2024 <br />
<a href='https://ojs.aaai.org/index.php/AAAI/article/view/28166'>[PDF]</a>
<a href='https://github.com/ru1ven/KeypointFusion'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="DIR"><img class="paper" src="paper/SYS.gif" title="Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image" />
<div> <strong>Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image</strong><br />
<strong>Pengfei Ren</strong>, Chao Wen, Xiaozheng Zheng, Zhou Xue, Haifeng Sun, Qi Qi, Jingyu Wang, Jianxin Liao <br />
International Conference on Computer Vision <strong>(ICCV, CCF-A)</strong>, <strong><font color="#FF0000">Oral</font></strong>, 2023 <br />
<a href='https://arxiv.org/abs/2302.02410'>[PDF]</a>
<a href='https://github.com/PengfeiRen96/DIR'>[Code]</a>
<a href='https://pengfeiren96.github.io/DIR/'>[HomePage]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="HaMuCo"><img class="paper" src="paper/HaMuCo.png" title="HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning" />
<div> <strong>HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning</strong><br />
Xiaozheng Zheng, Chao Wen, Zhou Xue, <strong>Pengfei Ren</strong>, Jingyu Wang <br />
International Conference on Computer Vision <strong>(ICCV, CCF-A)</strong>, 2023 <br />
<a href='https://arxiv.org/abs/2302.00988'>[PDF]</a>
<a href='https://github.com/zxz267/HaMuCo'>[Code]</a>
<a href='https://zxz267.github.io/HaMuCo/'>[HomePage]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="RDFNet"><img class="paper" src="paper/RDFNet.png" title="Region-Aware Dynamic Filtering Network for 3D Hand Reconstruction" />
<div> <strong>Region-Aware Dynamic Filtering Network for 3D Hand Reconstruction</strong><br />
Yuchen Chen, <strong>Pengfei Ren*</strong>, Jingyu Wang, Haifeng Sun, Qi Qi, Jing Wang, Jianxin Liao <br />
European Conference on Artificial Intelligence <strong>(ECAI, CCF-B)</strong>, <strong><font color="#FF0000">Oral</font></strong>, 2023 <br />
<a href='https://www.researchgate.net/publication/374300347_Region-Aware_Dynamic_Filtering_Network_for_3D_Hand_Reconstruction'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="IPNet"><img class="paper" src="paper/IPNet.png" title="Two Heads are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation" />
<div> <strong>Two Heads are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation</strong><br />
<strong>Pengfei Ren</strong>, Chenyu Chen, Jiachang Hao, Haifeng Sun, Qi Qi, Jingyu Wang, Jianxin Liao <br />
AAAI Conference on Artificial Intelligence <strong>(AAAI, CCF-A)</strong>, <strong><font color="#FF0000">Oral</font></strong>, 2023 <br />
<strong><font color="#FF0000">Distinguished Paper Award</font></strong> <br />
<a href='https://github.com/PengfeiRen96/PengfeiRen96.github.io/blob/master/paper/23AAAI-IPNet.pdf'>[PDF]</a>
<a href='https://github.com/PengfeiRen96/IPNet'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="SMR"><img class="paper" src="paper/SMR.png" title="SMR: Spatial-Guided Model-Based Regression for 3D Hand Pose and Mesh Reconstruction" />
<div> <strong>SMR: Spatial-Guided Model-Based Regression for 3D Hand Pose and Mesh Reconstruction</strong><br />
Haifeng Sun, Xiaozheng Zheng, <strong>Pengfei Ren</strong>, Jingyu Wang, Qi Qi, Jianxin Liao <br />
IEEE Transactions on Circuits and Systems for Video Technology <strong>(TCSVT, CCF-B)</strong>, 2023 <br />
<a href='https://ieeexplore.ieee.org/abstract/document/10147805'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="SA-Fusion"><img class="paper" src="paper/SA-Fusion.png" title="Multimodal Fusion Approach for Web-based Human-Computer Interaction in the Wild" />
<div> <strong>Multimodal Fusion Approach for Web-based Human-Computer Interaction in the Wild</strong><br />
Xingyu Liu, <strong>Pengfei Ren</strong>, Yuchen Chen, Cong Liu, Jing Wang, Haifeng Sun, Qi Qi, Jingyu Wang <br />
Proceedings of the ACM Web Conference <strong>(WWW, CCF-A)</strong>, 2023 <br />
<a href='https://dl.acm.org/doi/abs/10.1145/3543507.3587429'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="SV"><img class="paper" src="paper/SV.png" title="Can Shuffling Video Benefit Temporal Bias Problem: A Novel Training Framework for Temporal Grounding" />
<div> <strong>Can Shuffling Video Benefit Temporal Bias Problem: A Novel Training Framework for Temporal Grounding</strong><br />
Jiachang Hao, Haifeng Sun, <strong>Pengfei Ren</strong>, Jingyu Wang, Qi Qi, Jianxin Liao <br />
European Conference on Computer Vision <strong>(ECCV, CCF-B)</strong>, 2022 <br />
<a href='https://arxiv.org/pdf/2207.14698.pdf'>[PDF]</a>
<a href='https://github.com/haojc/ShufflingVideosForTSG'>[Code]</a>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="MMI"><img class="paper" src="paper/MMI.png" title="Mining Multi-View Information: A Strong Self-Supervised Framework for Depth-Based 3D Hand Pose and Mesh Estimation" />
<div> <strong>Mining Multi-View Information: A Strong Self-Supervised Framework for Depth-Based 3D Hand Pose and Mesh Estimation</strong><br />
<strong>Pengfei Ren</strong>, Haifeng Sun, Jiachang Hao, Jingyu Wang, Qi Qi, Jianxin Liao <br />
IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR, CCF-A)</strong>, 2022 <br />
<a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Mining_Multi-View_Information_A_Strong_Self-Supervised_Framework_for_Depth-Based_3D_CVPR_2022_paper.pdf'>[PDF]</a>
<a href='https://github.com/PengfeiRen96/MMI'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="DSF"><img class="paper" src="paper/DSF.png" title="A Dual-Branch Self-Boosting Framework for Self-Supervised 3D Hand Pose Estimation" />
<div> <strong>A Dual-Branch Self-Boosting Framework for Self-Supervised 3D Hand Pose Estimation</strong><br />
<strong>Pengfei Ren</strong>, Haifeng Sun, Jiachang Hao, Qi Qi, Jingyu Wang, Jianxin Liao <br />
IEEE Transactions on Image Processing <strong>(TIP, CCF-A)</strong>, 2022 <br />
<a href='https://ieeexplore.ieee.org/abstract/document/9841448/'>[PDF]</a>
<a href='https://github.com/PengfeiRen96/DSF'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

	

<div class="paper" id="SAR"><img class="paper" src="paper/SAR.png" title="SAR: Spatial-Aware Regression for 3D Hand Pose and Mesh Reconstruction from a Monocular RGB Image" />
<div> <strong>SAR: Spatial-Aware Regression for 3D Hand Pose and Mesh Reconstruction from a Monocular RGB Image</strong><br />
Xiaozheng Zheng, <strong>Pengfei Ren</strong>, Haifeng Sun, Jingyu Wang, Qi Qi, Jianxin Liao <br />
International Symposium on Mixed and Augmented Reality <strong>(ISMAR, CCF-B)</strong>, 2021 <br />
<a href='https://ieeexplore.ieee.org/document/9583792'>[PDF]</a>
<a href='https://github.com/zxz267/SAR'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="PHG"><img class="paper" src="paper/PHG.png" title="Pose-Guided Hierarchical Graph Reasoning for 3-D Hand Pose Estimation From a Single Depth Image" />
<div> <strong>Pose-Guided Hierarchical Graph Reasoning for 3-D Hand Pose Estimation From a Single Depth Image</strong><br />
<strong>Pengfei Ren</strong>, Haifeng Sun, Jiachang Hao, Qi Qi, Jingyu Wang, Jianxin Liao <br />
IEEE Transactions on Cybernetics <strong>(TCYB, CCF-B)</strong>, 2021 <br />
<a href='https://ieeexplore.ieee.org/abstract/document/9512523'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="SSRN"><img class="paper" src="paper/SSRN.png" title="Spatial-Aware Stacked Regression Network for Real-Time 3D Hand Pose Estimation" />
<div> <strong>Spatial-Aware Stacked Regression Network for Real-Time 3D Hand Pose Estimation</strong><br />
<strong>Pengfei Ren</strong>, Haifeng Sun, Weiting Huang, Jiachang Hao, Daixuan Cheng, Qi Qi, Jingyu Wang, Jianxin Liao <br />
Neurocomputing, 2021 <br />
<a href='https://www.sciencedirect.com/science/article/abs/pii/S0925231221000667'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

	
<div class="paper" id="AWR"><img class="paper" src="paper/AWR.png" title="AWR: Adaptive Weighting Regression for 3D Hand Pose Estimation" />
<div> <strong>AWR: Adaptive Weighting Regression for 3D Hand Pose Estimation</strong><br />
Weiting Huang, <strong>Pengfei Ren*</strong>, Jingyu Wang, Qi Qi, Haifeng Sun <br />
AAAI Conference on Artificial Intelligence <strong>(AAAI, CCF-A)</strong>, 2020 <br />
<a href='https://ojs.aaai.org/index.php/AAAI/article/view/6761'>[PDF]</a>
<a href='https://github.com/Elody-07/AWR-Adaptive-Weighting-Regression'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="SRN"><img class="paper" src="paper/SRN.gif" title=SRN: Stacked Regression Network for Real-time 3D Hand Pose Estimation." height="150" width="150"/>
<div> <strong>SRN: Stacked Regression Network for Real-time 3D Hand Pose Estimation.</strong><br />
<strong>Pengfei Ren</strong>, Haifeng Sun, Qi Qi, Jingyu Wang, Weiting Huang<br />
British Machine Vision Virtual Conference  <strong>(BMVC, CCF-C)</strong>, 2019<br />
<a href='https://bmvc2019.org/wp-content/uploads/papers/0918-paper.pdf'>[PDF]</a>
<a href='https://github.com/PengfeiRen96/SRN'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Honors and Awards</h2>
<div class="paper">
<ul>
<li>  <font color="#FF0000"> <strong> The Outstanding Ph.D. thesis of China Education Society of Electronic (CESE), 2024 </strong></font> </li>
<li>  <font color="#FF0000"> <strong> The Outstanding Ph.D. thesis of Beijing University of Posts and Telecommunications (BUPT), 2023 </strong></font> </li>
<li>  <font color="#FF0000"> <strong> The Distinguished Paper Award of AAAI, 2023 </strong></font> </li>
<li> JingDong Outstanding Doctoral Scholarship, 2021 </li>
<li> The First Prize Doctoral Scholarship, 2021, 2022 </li>
</ul>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Academic Service</h2>
<div class="paper">
<ul>
<p><strong><font size="5"> Journals</font></p></strong>
<p><font size="5"> IEEE Transaction on Image Processing (TIP)</font></p>
<p><font size="5"> IEEE Transactions on Multimedia (TMM)</font></p>
<p><font size="5"> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</font></p>
<p><font size="5"> Neurocomputing </font></p>
<p><strong><font size="5"> Conferences</font></p></strong>
<p><font size="5">CVPR, ICCV, ECCV, AAAI, ISMAR, etc.</font></p>
</ul>
</div>
</div>
</div>

<!--
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Contests</h2>
<div class="paper">
<ul>
<li><strong>Large-scale Scene Understanding Challenge: <a href='http://gesture.chalearn.org/'>Scene Classification</a></strong> (<small>CVPR2015 workshop</small>),  <strong>Rank</strong>: 2/4</li>
<li><strong>National Graduate Contest on Smart-City Technology and Creative Design: <a href='http://avid.erangelab.com/'>Face Detection</a></strong>,  <strong>Rank</strong>: 2/10.</li>

<li><strong>The First-class Prize of China Undergraduate Mathematical Contest in Modeling</strong> </li>

</ul>
<div class="spanner"></div>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section"><h2>Awards</h2>
<div class="paper">
<li><strong>“National Scholarship”, 2013/2014</li>
</div>
</div>
</div>
-->


<div style="clear:both;">
<p align="right"><font size="5">Last Updated on June, 2023</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>

<hr>
<div id="clustrmaps-widget">
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=EhePmkYUAykrIyCmrnxAOZZdzMg_BNS_WAD8KA2GDgg&cl=ffffff&w=a"></script>
</div>
</body>
</html>
